{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping and Threshold Stopping\n",
    "\n",
    "In composer, Callbacks modify trainer behavior and are called at the relevent Events in the training loop. This tutorial focuses on two callbacks, the EarlyStopper and ThresholdStopper, both of which halt training early depending on different criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll train a ComposerModel and halt training for criteria that we'll set. We'll use the same model and setup in the \"Getting Up and Running with Composer\" tutorial.\n",
    "\n",
    "First, install composer if you haven't already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mosaicml \n",
    "\n",
    "import torch\n",
    "import composer\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../data\"\n",
    "\n",
    "# Normalization constants\n",
    "mean = (0.507, 0.487, 0.441)\n",
    "std = (0.267, 0.256, 0.276)\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "cifar10_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(data_directory, train=True, download=True, transform=cifar10_transforms)\n",
    "test_dataset = datasets.CIFAR10(data_directory, train=False, download=True, transform=cifar10_transforms)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Optimizer, Scheduler Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer import models\n",
    "\n",
    "model = models.ComposerResNetCIFAR(model_name='resnet_56', num_classes=10)\n",
    "\n",
    "optimizer = composer.optim.DecoupledSGDW(\n",
    "    model.parameters(), # Model parameters to update\n",
    "    lr=0.05, # Peak learning rate\n",
    "    momentum=0.9,\n",
    "    weight_decay=2.0e-3 # If this looks large, it's because its not scaled by the LR as in non-decoupled weight decay\n",
    ")\n",
    "\n",
    "lr_scheduler = composer.optim.LinearWithWarmupScheduler(\n",
    "    t_warmup=\"1ep\", # Warm up over 1 epoch\n",
    "    alpha_i=1.0, # Flat LR schedule achieved by having alpha_i == alpha_f\n",
    "    alpha_f=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EarlyStopper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EarlyStopper callback tracks a particular training or evaluation metric and stops training if the metric does not improve within a given time interval. \n",
    "\n",
    "\n",
    "Here, we'll use it track the Accuracy metric and set it set the patience val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EarlyStopper takes several parameters. Here are the one's we'll use in this tutorial:\n",
    "-  monitor: The string name of the metric to track\n",
    "\n",
    "- dataloader_label: The dataloader_label identifies which specific metric to use. For example, for the trainer to track the Accuracy metric associated with the test dataset, the dataloader_label distinguishes the metric to track. In our example, our dataloader_label has to be the same as the label in our Evaluator, \"test_eval_label\". When not using \n",
    "Evaluators, the dataloader_labels, are usually set to \"train\" and \"eval\".\n",
    "\n",
    "- patience: The interval of the time that the EarlyStopper will wait before stopping training if the metric is not improving. You can use integers to specify the number of epochs or use the units of time specified in the Composer Time library ex, \"50ba\", \"2ep\" for 50 batches and 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopper(monitor=\"Accuracy\", dataloader_label=\"test_eval_label\", patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several other parameters you can specify:\n",
    "- min_delta: If the min_delta is a non zero value, the EarlyStopper will still halt training if the change in the metric is smaller than min_delta value. \n",
    "\n",
    "- comp: A comparison operator can be provided toe measure change in the monitored metric. The comparison operator will be called comp(current_value, previous_best)\n",
    "\n",
    "More details can be found in the documentation for the EarlyStopper callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.callbacks.early_stopper import EarlyStopper\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "from composer.core import Evaluator\n",
    "\n",
    "\n",
    "early_stopper = EarlyStopper(\"Accuracy\", \"test_eval_label\", patience=1)\n",
    "evaluator = Evaluator(\n",
    "    dataloader = test_dataloader,\n",
    "    label = \"test_evaluator\",\n",
    "    metrics = Accuracy()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our EarlyStopper callback object tracking our Evauator metric, we can instantiate our Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = \"3ep\" # Train for 3 epochs because we're assuming Colab environment and hardware\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\" # select the device\n",
    "\n",
    "trainer = composer.trainer.Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=evaluator,\n",
    "    max_duration=train_epochs,\n",
    "    optimizers=optimizer,\n",
    "    schedulers=lr_scheduler,\n",
    "    device=device,\n",
    "    callbacks=[early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThresholdStopper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ThresholdStopper is similar to the EarlyStopper, but it halts training when the metric crosses a threshold set in the ThresholdStopper callback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for the ThresholdStopper are similar to the EarlyStopper. See the above descriptions of the `monitor`, and `dataloader_label`, and `comp`\n",
    "\n",
    "The other parameters are:\n",
    "- threshold: The float threshold that dictates when the halt training.\n",
    "\n",
    "- stop_on_batch: If stop_on_batch is specified, training will halt in the middle of training if the training metrics satisfy the training metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse the same setup for the ThresholdStopper example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.callbacks.threshold_stopper import ThresholdStopper\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "\n",
    "threshold_stopper = ThresholdStopper(\"Accuracy\", \"test_eval_label\", threshold=0.65)\n",
    "evaluator = Evaluator(\n",
    "    dataloader = test_dataloader,\n",
    "    label = \"test_evaluator\",\n",
    "    metrics = Accuracy()\n",
    ")\n",
    "\n",
    "train_epochs = \"3ep\" # Train for 3 epochs because we're assuming Colab environment and hardware\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\" # select the device\n",
    "\n",
    "trainer = composer.trainer.Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=evaluator,\n",
    "    max_duration=train_epochs,\n",
    "    optimizers=optimizer,\n",
    "    schedulers=lr_scheduler,\n",
    "    device=device,\n",
    "    callbacks=[threshold_stopper]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
